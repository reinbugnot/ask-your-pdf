{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a91d85-ec70-4c02-9ff3-0663464da4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings  # Updated import\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb2d52d-f4b1-45d1-9437-df5c12c109e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY_NUS\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f48a43-627a-4082-8053-b6fb809f6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDF document\n",
    "loader = PyPDFLoader(file_path=\"./data/CERT_RAG.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split the document into manageable chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b5e7b7a-13e0-4190-bb1a-740cf471a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store using FAISS\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "# Set up the retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4b2c00-4bf5-4e8b-8599-276a227838c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build retriever tool ###\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"pdf_retriever\",\n",
    "    \"Searches and returns excerpts from the uploaded PDF document.\",\n",
    ")\n",
    "tools = [tool]\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6135eaf-079e-4839-8e9e-f13f131532b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_question_from_txt(file_path):\n",
    "    # Read the contents of the .txt file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Extract the question and choices\n",
    "    question = lines[0].strip()  # First line is the question\n",
    "    choice_a = lines[1].strip()  # Second line is choice A\n",
    "    choice_b = lines[2].strip()  # Third line is choice B\n",
    "    choice_c = lines[3].strip()  # Fourth line is choice C\n",
    "    choice_d = lines[4].strip()  # Fifth line is choice D\n",
    "\n",
    "    # Format the query string\n",
    "    query = f\"{question}\\n (a) {choice_a}\\n (b) {choice_b}\\n (c) {choice_c}\\n (d) {choice_d}\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f0b49b-9af8-4e61-989c-21e4c2af9e6e",
   "metadata": {},
   "source": [
    "### Run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1684a13-cab7-4b6e-bde3-92ba3e2dca93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "whaat is one way to understand current WIP in a system?\n",
      " (a) pair to complete the work faster\n",
      " (b) make current work visible\n",
      " (c) split stories\n",
      " (d) size stories smaller\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  pdf_retriever (call_dwR1IA0OSbiI4cPP2kjiFtU1)\n",
      " Call ID: call_dwR1IA0OSbiI4cPP2kjiFtU1\n",
      "  Args:\n",
      "    query: understand current WIP in a system\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: pdf_retriever\n",
      "\n",
      "The first corrective action is to make the current WIP visible to all stakeholders. Figure 2 shows a\n",
      "simple Kanban board that illustrates the total amount of WIP and the process state of each work\n",
      "item. This Kanban serves as an initial process diagnostic, showing the current bottlenecks. Often,\n",
      "simply visualizing the current volume of work is the wake-up call that causes the organization to\n",
      "address the systemic problems of too much work and too little flow.\n",
      "\n",
      "Review Build Test Done\n",
      "© Scaled Agile, Inc.\n",
      "Figur e 2. Kanb an bo ards mak e excessiv e work-in-pr ocess (WIP) visible\n",
      "The following action is balancing the amount of WIP against the available development capacity.\n",
      "This is done by establishing—and continually adjusting—WIP limits for the relevant states. No new\n",
      "work is started when any workflow state reaches its WIP limit. This matches demand to capacity\n",
      "and increases flow through the system.\n",
      "Limiting WIP, however, requires knowledge, discipline, and commitment. It may even seem\n",
      "counterintuitive to those who believe that the more work you put into the system, the more you\n",
      "get out. That can be true up to a point, but when the system becomes overloaded, throughput\n",
      "decreases dramatically. Indeed, there is no substitute for effectively managing WIP.\n",
      "#2 Addr ess Bottlenecks\n",
      "Bottlenecks occur wherever people or resources (systems, materials, and so on) in the flow of\n",
      "\n",
      "powerful accelerators of value are relevant to all Framework levels, but the challenges differ for\n",
      "each. An individual SAFe article discusses how these accelerators apply to each flow domain: Team\n",
      "Flow, ART Flow , Solution T rain Flow , and Portfolio Flow .\n",
      "#1 Visualize and Limit WIP\n",
      "Overloading teams and AR Ts with more work than can be reasonably accomplished is a common\n",
      "and pernicious problem. T oo much work in process (WIP) confuses priorities, causes frequent\n",
      "context switching, and increases overhead. It overloads people, scatters focus on immediate tasks,\n",
      "reduces productivity and throughput, and increases wait times for new functionality. Like a\n",
      "highway at rush hour, there is simply no upside to having more work in a system than the system\n",
      "can handle.\n",
      "The first corrective action is to make the current WIP visible to all stakeholders. Figure 2 shows a\n",
      "simple Kanban board that illustrates the total amount of WIP and the process state of each work\n",
      "\n",
      "properties, as illustrated in Figure 1.\n",
      "BottleneckWork-in-Process (WIP)\n",
      "BatchHand-offQueue\n",
      "Policies !\n",
      "WorkerFeedback\n",
      "© Scaled Agile, Inc.1\n",
      "234\n",
      "5\n",
      "76\n",
      "8\n",
      "Figur e 1. Eight pr oper ties o f a flow syst em\n",
      "Each is described briefly below:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "One way to understand current Work In Progress (WIP) in a system is to:\n",
      "\n",
      "**(b) make current work visible**\n",
      "\n",
      "Making the current WIP visible to all stakeholders, such as through a Kanban board, helps identify bottlenecks and manage the flow of work effectively.\n"
     ]
    }
   ],
   "source": [
    "file_path = './rag-input.txt'\n",
    "query = read_question_from_txt(file_path)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "for event in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=query)]},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e983f2-6bbe-4395-a831-923290f46feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
